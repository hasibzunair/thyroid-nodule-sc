{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trains a baseline U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name data and config types\n",
    "DATASET_NAME = \"data0\" # name of the npz file\n",
    "CFG_NAME = \"unet\" # name of the architecture/configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping, ReduceLROnPlateau\n",
    "from keras import callbacks\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "# Go back one step to read module\n",
    "import sys\n",
    "sys.path.insert(0,\"..\") \n",
    "\n",
    "import models as M\n",
    "import losses as l\n",
    "\n",
    "ROOT_DIR = os.path.abspath(\"../\")\n",
    "DATASET_FOLDER = \"npy_data\"\n",
    "DATASET_PATH = os.path.join(ROOT_DIR, \"datasets\", DATASET_FOLDER)\n",
    "EXPERIMENT_NAME = \"{}_{}\".format(DATASET_NAME, CFG_NAME)\n",
    "\n",
    "\n",
    "if not os.path.exists(os.path.join(ROOT_DIR, \"logs\")):\n",
    "    os.mkdir(os.path.join(ROOT_DIR, \"logs\"))\n",
    "\n",
    "# Make log path to store all results\n",
    "LOG_PATH = os.path.join(ROOT_DIR, \"logs\", EXPERIMENT_NAME)\n",
    "\n",
    "if not os.path.exists(LOG_PATH):\n",
    "    os.mkdir(LOG_PATH)\n",
    "    \n",
    "print(os.listdir(DATASET_PATH))\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "data = np.load(DATASET_PATH + '/{}.npz'.format(DATASET_NAME))\n",
    "train_data = data['name1']\n",
    "train_labels = data['name2']\n",
    "train_data = np.expand_dims(train_data, axis=-1)\n",
    "train_labels = np.minimum(train_labels, 1)\n",
    "train_labels = np.expand_dims(train_labels, axis=-1)\n",
    "print(train_data.shape, train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, mask in zip(train_data[:3], train_labels[:3]):\n",
    "    \n",
    "    img = np.squeeze(img, axis=-1) # change to H, W\n",
    "    mask = np.squeeze(mask, axis=-1) # change to H, W\n",
    "    \n",
    "    \n",
    "    fig,_ = plt.subplots(nrows=1, ncols=2, figsize=(14,12))\n",
    "    fig.axes[0].imshow(img, cmap='gray')\n",
    "    fig.axes[1].imshow(mask, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot and save accuravy loss graphs individually\n",
    "def plot_loss_accu(history):\n",
    "    loss = history.history['loss'][1:]\n",
    "    val_loss = history.history['val_loss'][1:]\n",
    "    epochs = range(len(loss))\n",
    "    plt.plot(epochs, loss, 'g')\n",
    "    plt.plot(epochs, val_loss, 'y')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.ylabel('Loss %')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['training', 'validation'], loc='upper right')\n",
    "    plt.grid(True)\n",
    "    plt.savefig('{}/{}_loss.png'.format(LOG_PATH, EXPERIMENT_NAME), dpi=100)\n",
    "    plt.show()\n",
    "    \n",
    "    loss = history.history['jacard'][1:]\n",
    "    val_loss = history.history['val_jacard'][1:]\n",
    "    epochs = range(len(loss))\n",
    "    plt.plot(epochs, loss, 'r')\n",
    "    plt.plot(epochs, val_loss, 'b')\n",
    "    plt.title('Training and validation jaccard index')\n",
    "    plt.ylabel('Jaccard Index %')\n",
    "    #plt.xlabel('Epoch')\n",
    "    plt.legend(['training', 'validation'], loc='lower right')\n",
    "    plt.grid(True)\n",
    "    plt.savefig('{}/{}_jac.png'.format(LOG_PATH, EXPERIMENT_NAME), dpi=100)\n",
    "    plt.show()\n",
    "    \n",
    "    loss = history.history['dice'][1:]\n",
    "    val_loss = history.history['val_dice'][1:]\n",
    "    epochs = range(len(loss))\n",
    "    plt.plot(epochs, loss, 'r')\n",
    "    plt.plot(epochs, val_loss, 'b')\n",
    "    plt.title('Training and validation dice')\n",
    "    plt.ylabel('Dice Score %')\n",
    "    #plt.xlabel('Epoch')\n",
    "    plt.legend(['training', 'validation'], loc='lower right')\n",
    "    plt.grid(True)\n",
    "    plt.savefig('{}/{}_jac.png'.format(LOG_PATH, EXPERIMENT_NAME), dpi=100)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_graphs(history):\n",
    "    \n",
    "    # b, g, r, y, o, -g, -m\n",
    "    \n",
    "    experiment_name = EXPERIMENT_NAME\n",
    "    plt.figure(figsize=(18, 5))\n",
    "    plt.subplot(131)\n",
    "    plt.plot(history.history['loss'],linewidth=4)\n",
    "    plt.plot(history.history['val_loss'],linewidth=4)\n",
    "    plt.title('{} loss'.format(experiment_name))\n",
    "    #plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.grid(True)\n",
    "\n",
    "    \n",
    "\n",
    "    plt.subplot(132)\n",
    "    plt.plot(history.history['jacard'],linewidth=4)\n",
    "    plt.plot(history.history['val_jacard'],linewidth=4)\n",
    "    plt.title('{} Jacard'.format(experiment_name))\n",
    "    #plt.ylabel('Jacard')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.grid(True)\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "\n",
    "\n",
    "\n",
    "    plt.subplot(133)\n",
    "    plt.plot(history.history['dice_coef'],linewidth=4)\n",
    "    plt.plot(history.history['val_dice_coef'],linewidth=4)\n",
    "    plt.title('{} Dice'.format(experiment_name))\n",
    "    #plt.ylabel('Dice')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.grid(True)\n",
    "    plt.savefig('{}/{}_graph.png'.format(LOG_PATH, EXPERIMENT_NAME), dpi=100)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build standard U-Net model\n",
    "model = M.unet(input_size = (train_data.shape[1], train_data.shape[2], train_data.shape[-1]))\n",
    "\n",
    "# Build U-Net model with custom encoder\n",
    "#backbone_name = 'vgg16'\n",
    "#encoder_weights = None\n",
    "#model = M.unet_backbone(backbone=backbone_name, input_size = (train_data.shape[1], \n",
    "#            train_data.shape[2], train_data.shape[-1]), encoder_weights=encoder_weights)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "weights_path = \"{}/{}.h5\".format(LOG_PATH, EXPERIMENT_NAME)\n",
    "checkpointer = ModelCheckpoint(filepath=weights_path, verbose=1, monitor='val_jacard', mode='max', save_best_only=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_jacard', factor=0.1, patience=5, verbose=1, min_lr=1e-8, mode='max') # new_lr = lr * factor\n",
    "early_stopping = EarlyStopping(monitor='val_jacard', min_delta=0, verbose=1, patience=8, mode='max', restore_best_weights=True)\n",
    "csv_logger = CSVLogger('{}/{}_training.csv'.format(LOG_PATH, EXPERIMENT_NAME))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and validation sets\n",
    "x_train = train_data[:2915]\n",
    "x_test = train_data[2915:]\n",
    "y_train = train_labels[:2915]\n",
    "y_test = train_labels[2915:]\n",
    "print(\"Train and validate on -------> \", x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "batch_size = 16 \n",
    "epochs = 100000\n",
    "model.fit(x_train, y_train,\n",
    "                batch_size=batch_size,\n",
    "                epochs=epochs,\n",
    "                validation_data=(x_test, y_test),\n",
    "                callbacks=[checkpointer, early_stopping, reduce_lr, csv_logger],\n",
    "                shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log training history\n",
    "plot_graphs(model.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate trained model using Jaccard and Dice metric\n",
    "from tensorflow.keras.models import load_model\n",
    "model = None\n",
    "model = load_model(weights_path, compile=False)\n",
    "yp = model.predict(x=x_test, batch_size=16, verbose=1)\n",
    "#Round off boolean masks\n",
    "yp = np.round(yp,0)\n",
    "yp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape, yp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval on train set\n",
    "yp_t = None\n",
    "yp_t = model.predict(x=x_train, batch_size=16, verbose=0)\n",
    "#Round off boolean masks\n",
    "yp_t = np.round(yp_t,0)\n",
    "yp_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp_t.shape, yp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('{}/{}_{}_mask_pred.npz'.format(LOG_PATH, CFG_NAME, DATASET_NAME), \n",
    "         name1=y_train, name2=y_test, name3=yp_t, name4=yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary segmentation\n",
    "\n",
    "try:\n",
    "    os.makedirs('{}/results/'.format(LOG_PATH, EXPERIMENT_NAME))\n",
    "except:\n",
    "    pass \n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.subplot(1,3,1)\n",
    "    if len(x_test[i].shape) >= 2:\n",
    "        plt.grid(False)\n",
    "        plt.imshow(x_test[i].squeeze(), cmap='gray') # 1-channel image\n",
    "    else:\n",
    "        plt.grid(False)\n",
    "        plt.imshow(x_test[i]) # 3-channel\n",
    "        \n",
    "    plt.title('Input')\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.grid(False)\n",
    "    plt.imshow(y_test[i].reshape(y_test[i].shape[0],y_test[i].shape[1]), cmap='magma') #cmap='magma'\n",
    "    plt.title('Ground Truth')\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.grid(False)\n",
    "    plt.imshow(yp[i].reshape(yp[i].shape[0],yp[i].shape[1]),cmap='magma')\n",
    "    plt.title('Prediction')\n",
    "    \n",
    "    # Calc jaccard index of predictions\n",
    "    intersection = yp[i].ravel() * y_test[i].ravel()\n",
    "    union = yp[i].ravel() + y_test[i].ravel() - intersection\n",
    "    jacard = (np.sum(intersection)/np.sum(union))  \n",
    "    \n",
    "    plt.suptitle('Jacard Index: '+ str(np.sum(intersection)) +'/'+ str(np.sum(union)) +' = '+str(jacard))\n",
    "    plt.savefig('{}/results/'.format(LOG_PATH, EXPERIMENT_NAME)+str(i)+'.png',format='png')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
