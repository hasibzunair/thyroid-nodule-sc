{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trains a baseline U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name data and config types\n",
    "DATASET_NAME = \"test\"\n",
    "CFG_NAME = \"unet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping, ReduceLROnPlateau\n",
    "from keras import callbacks\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "# Go back one step to read module\n",
    "import sys\n",
    "sys.path.insert(0,\"..\") \n",
    "\n",
    "import models as M\n",
    "import losses as l\n",
    "\n",
    "ROOT_DIR = os.path.abspath(\"../\")\n",
    "DATASET_FOLDER = \"npys\"\n",
    "DATASET_PATH = os.path.join(ROOT_DIR, \"datasets\", DATASET_FOLDER)\n",
    "EXPERIMENT_NAME = \"{}_{}\".format(DATASET_NAME, CFG_NAME)\n",
    "\n",
    "\n",
    "if not os.path.exists(os.path.join(ROOT_DIR, \"logs\")):\n",
    "    os.mkdir(os.path.join(ROOT_DIR, \"logs\"))\n",
    "\n",
    "# Make log path to store all results\n",
    "LOG_PATH = os.path.join(ROOT_DIR, \"logs\", EXPERIMENT_NAME)\n",
    "\n",
    "if not os.path.exists(LOG_PATH):\n",
    "    os.mkdir(LOG_PATH)\n",
    "    \n",
    "print(os.listdir(DATASET_PATH))\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "train_data = np.load(\"{}/{}_img.npy\".format(DATASET_PATH, DATASET_NAME)) \n",
    "train_labels = np.load(\"{}/{}_mask.npy\".format(DATASET_PATH, DATASET_NAME))\n",
    "print(train_data.shape, train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot and save accuravy loss graphs individually\n",
    "def plot_loss_accu(history):\n",
    "    loss = history.history['loss'][1:]\n",
    "    val_loss = history.history['val_loss'][1:]\n",
    "    epochs = range(len(loss))\n",
    "    plt.plot(epochs, loss, 'g')\n",
    "    plt.plot(epochs, val_loss, 'y')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.ylabel('Loss %')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['training', 'validation'], loc='upper right')\n",
    "    plt.grid(True)\n",
    "    #plt.savefig('{}/{}_loss.jpg'.format(output_path, EXP_NAME), dpi=100)\n",
    "    plt.savefig('{}/{}_loss_graph.pdf'.format(LOG_PATH, EXPERIMENT_NAME), dpi=100)\n",
    "    plt.show()\n",
    "    \n",
    "    loss = history.history['jacard'][1:]\n",
    "    val_loss = history.history['val_jacard'][1:]\n",
    "    epochs = range(len(loss))\n",
    "    plt.plot(epochs, loss, 'r')\n",
    "    plt.plot(epochs, val_loss, 'b')\n",
    "    plt.title('Training and validation jaccard index')\n",
    "    plt.ylabel('Accuracy %')\n",
    "    #plt.xlabel('Epoch')\n",
    "    plt.legend(['training', 'validation'], loc='lower right')\n",
    "    plt.grid(True)\n",
    "    #plt.savefig('{}/{}_acc.jpg'.format(output_path, EXP_NAME), dpi=100)\n",
    "    plt.savefig('{}/{}_jac_graph.pdf'.format(LOG_PATH, EXPERIMENT_NAME), dpi=100)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "model = M.unet(input_size = (train_data.shape[1], train_data.shape[2], train_data.shape[-1]))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "weights_path = \"{}/{}.h5\".format(LOG_PATH, EXPERIMENT_NAME)\n",
    "checkpointer = ModelCheckpoint(filepath=weights_path, verbose=0, monitor='val_jacard', mode='max', save_best_only=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_jacard', factor=0.1, patience=8, verbose=1, min_lr=1e-8, mode='max') # new_lr = lr * factor\n",
    "early_stopping = EarlyStopping(monitor='val_jacard', min_delta=0, verbose=1, patience=10, mode='max', restore_best_weights=True)\n",
    "csv_logger = CSVLogger('{}/{}_training.csv'.format(LOG_PATH, EXPERIMENT_NAME))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store results from multiple runs\n",
    "jacs = []\n",
    "dices = []\n",
    "all_epochs = []\n",
    "losses = []\n",
    "\n",
    "best_jac = 0\n",
    "\n",
    "# Calculate the starting time    \n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    # Split the data\n",
    "    indices=list(range(len(train_data)))\n",
    "    np.random.shuffle(indices)\n",
    "    ind=int(len(indices)*0.80)\n",
    "    train = indices[:ind]\n",
    "    test = indices[-(len(indices)-ind):]\n",
    "\n",
    "    x_train = train_data[train]\n",
    "    x_test = train_data[test]\n",
    "    y_train = train_labels[train]\n",
    "    y_test = train_labels[test]\n",
    "\n",
    "    print(\"Fold {} train on -------> \".format(i), x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
    "    \n",
    "    # Clearing the NN.\n",
    "    K.clear_session()\n",
    "    model = None \n",
    "    \n",
    "    # Define the model\n",
    "    model = M.unet(input_size = (train_data.shape[1], train_data.shape[2], train_data.shape[-1]))\n",
    "    \n",
    "    # Train\n",
    "    batch_size = 16 \n",
    "    epochs = 100000\n",
    "    model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=[early_stopping, reduce_lr],\n",
    "                    shuffle=True)\n",
    "    \n",
    "    \n",
    "    # Log number of epochs to train and minimum loss\n",
    "    total_epochs = len(model.history.history['loss'])\n",
    "    min_loss = min(model.history.history['val_loss'])\n",
    "    all_epochs.append(total_epochs)\n",
    "    losses.append(min_loss)\n",
    "\n",
    "    # Evaluate trained model using Jaccard and Dice metric\n",
    "    yp = None\n",
    "    yp = model.predict(x=x_test, batch_size=batch_size, verbose=0)\n",
    "    #Round off boolean masks\n",
    "    yp = np.round(yp,0) \n",
    "\n",
    "    jacard = 0\n",
    "    dice = 0\n",
    "    \n",
    "    for i in range(len(y_test)):\n",
    "        yp_2 = yp[i].ravel()\n",
    "        y2 = y_test[i].ravel()\n",
    "\n",
    "        intersection = yp_2 * y2\n",
    "        union = yp_2 + y2 - intersection\n",
    "\n",
    "        jacard += (np.sum(intersection)/np.sum(union))  \n",
    "        dice += (2. * np.sum(intersection) ) / (np.sum(yp_2) + np.sum(y2))\n",
    "\n",
    "    jacard /= len(y_test)\n",
    "    dice /= len(y_test)\n",
    "\n",
    "    print('Jacard Index : '+str(jacard))\n",
    "    print('Dice Coefficient : '+str(dice))\n",
    "    \n",
    "    jacs.append(jacard)\n",
    "    dices.append(dice)\n",
    "    \n",
    "    if jacard > best_jac:\n",
    "        \n",
    "        print('***********************************************')\n",
    "        print('Jacard Index improved from '+str(best_jac)+' to '+str(jacard))\n",
    "        print('***********************************************')\n",
    "        # Save model\n",
    "        model.save(weights_path)\n",
    "        \n",
    "        # Save loss\n",
    "        loss_history = model.history.history[\"val_loss\"]\n",
    "        loss_history = np.array(loss_history)\n",
    "        np.savetxt(\"{}/{}_loss.txt\".format(LOG_PATH, EXPERIMENT_NAME), loss_history, delimiter=\",\")\n",
    "        \n",
    "        # Save jaccard\n",
    "        jacard_history = model.history.history[\"val_jacard\"]\n",
    "        jacard_history = np.array(jacard_history)\n",
    "        np.savetxt(\"{}/{}_jacard.txt\".format(LOG_PATH, EXPERIMENT_NAME), jacard_history, delimiter=\",\")\n",
    "        \n",
    "        # Save images, masks, and predicted masks\n",
    "        np.save(\"{}/{}_inputs.npy\".format(LOG_PATH, EXPERIMENT_NAME), x_test)\n",
    "        np.save(\"{}/{}_masks.npy\".format(LOG_PATH, EXPERIMENT_NAME), y_test)\n",
    "        np.save(\"{}/{}_predicted_masks.npy\".format(LOG_PATH, EXPERIMENT_NAME), yp)\n",
    "        \n",
    "        # Log training history\n",
    "        plot_loss_accu(model.history)\n",
    "        \n",
    "        final_images = x_test\n",
    "        final_masks = y_test\n",
    "        final_preds = yp\n",
    "        \n",
    "        best_jac = jacard\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"--- Time taken to train : %s hours ---\" % ((end_time - start_time)//3600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jacs = [x * 100 for x in jacs]\n",
    "dices = [x * 100 for x in dices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jacs, dices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Jaccard: %.4f%% (+/- %.4f%%)\" % (np.mean(jacs), np.std(jacs)))\n",
    "print(\"Dice: %.4f%% (+/- %.4f%%)\" % (np.mean(dices), np.std(dices)))\n",
    "print(\"Epochs: %.4f%% (+/- %.4f%%)\" % (np.mean(all_epochs), np.std(all_epochs)))\n",
    "print(\"Loss: %.4f%% (+/- %.4f%%)\" % (np.mean(losses), np.std(losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store report\n",
    "\n",
    "report = {}\n",
    "\n",
    "report['Mean Jaccard + Std = '] = (\"%.4f%% +/- %.4f%%\" % (np.mean(jacs), np.std(jacs)))\n",
    "report['Mean Dice + Std = '] = (\"%.4f%% +/- %.4f%%\" % (np.mean(dices), np.std(dices)))\n",
    "report['Mean Epoch + Std = '] = (\"%.4f%% +/- %.4f%%\" % (np.mean(all_epochs), np.std(all_epochs)))\n",
    "report['Mean Loss + Std = '] = (\"%.4f%% +/- %.4f%%\" % (np.mean(losses), np.std(losses)))\n",
    "\n",
    "with open(\"{}/{}_REPORT.txt\".format(LOG_PATH, EXPERIMENT_NAME), 'w') as f:\n",
    "    for k,v in report.items():\n",
    "        f.write(str(k))\n",
    "        #f.write(\"--->\")\n",
    "        f.write(str(v))\n",
    "        \n",
    "        # new line\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = loss_history\n",
    "j = jacard_history\n",
    "epochs = range(len(j))\n",
    "plt.plot(epochs, l, 'g')\n",
    "plt.plot(epochs, j, 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = final_images\n",
    "y_test = final_masks\n",
    "yp = final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary segmentation\n",
    "\n",
    "try:\n",
    "    os.makedirs('{}/results/'.format(LOG_PATH, EXPERIMENT_NAME))\n",
    "except:\n",
    "    pass \n",
    "\n",
    "for i in range(20):\n",
    "    \n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.subplot(1,3,1)\n",
    "    if len(x_test[i].shape) >= 2:\n",
    "        plt.grid(False)\n",
    "        plt.imshow(x_test[i].squeeze(), cmap='gray') # 1-channel image\n",
    "    else:\n",
    "        plt.grid(False)\n",
    "        plt.imshow(x_test[i]) # 3-channel\n",
    "        \n",
    "    plt.title('Input')\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.grid(False)\n",
    "    plt.imshow(y_test[i].reshape(y_test[i].shape[0],y_test[i].shape[1]), cmap='magma') #cmap='magma'\n",
    "    plt.title('Ground Truth')\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.grid(False)\n",
    "    plt.imshow(yp[i].reshape(yp[i].shape[0],yp[i].shape[1]),cmap='magma')\n",
    "    plt.title('Prediction')\n",
    "    \n",
    "    # Calc jaccard index of predictions\n",
    "    intersection = yp[i].ravel() * y_test[i].ravel()\n",
    "    union = yp[i].ravel() + y_test[i].ravel() - intersection\n",
    "    jacard = (np.sum(intersection)/np.sum(union))  \n",
    "    \n",
    "    plt.suptitle('Jacard Index: '+ str(np.sum(intersection)) +'/'+ str(np.sum(union)) +' = '+str(jacard))\n",
    "    plt.savefig('{}/results/'.format(LOG_PATH, EXPERIMENT_NAME)+str(i)+'.png',format='png')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
